{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Lambda, MaxPooling2D, Rescaling # convolution layers\n",
    "from keras.layers import Dense, Dropout, Flatten # core layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import json\n",
    "\n",
    "from utils import plot_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (58, 58)\n",
    "\n",
    "adaptive_based_on_val = True  # if False, then uses ada_delta with decay, else uses stopping and decay based on val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adaptive_based_on_val:\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        \"images2/train\",\n",
    "        validation_split=0.1,\n",
    "        subset=\"training\",\n",
    "        seed=20,\n",
    "        color_mode='rgb',\n",
    "        image_size=input_shape,\n",
    "        label_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        \"images2/train\",\n",
    "        validation_split=0.1,\n",
    "        subset=\"validation\",\n",
    "        seed=20,\n",
    "        color_mode='rgb',\n",
    "        image_size=input_shape,\n",
    "        batch_size=64,\n",
    "        label_mode=\"categorical\",\n",
    "        shuffle=False,\n",
    "    )\n",
    "else:\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        \"images2/train\",\n",
    "        seed=42,\n",
    "        color_mode='rgb',\n",
    "        image_size=input_shape,\n",
    "        label_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "        batch_size=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Rescaling(1./127.5, offset=-1, input_shape=(input_shape[0], input_shape[1], 3)))\n",
    "model.add(Conv2D(filters=64, kernel_size = (6,6), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())    \n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "    \n",
    "model.add(Dense(9,activation=\"softmax\"))\n",
    "if adaptive_based_on_val:\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "else:\n",
    "    ada_delta_ = keras.optimizers.Adadelta(lr=1, rho=0.95, epsilon=1e-08, decay=0.03)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=ada_delta_, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adaptive_based_on_val:\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", # metrics to monitor\n",
    "        patience=10, # how many epochs before stop\n",
    "        verbose=1,\n",
    "        mode=\"max\", # we need the maximum accuracy.\n",
    "        restore_best_weights=True, # \n",
    "        )\n",
    "\n",
    "    rp = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_accuracy\",\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode=\"max\",\n",
    "        min_lr=0.00001,\n",
    "        )\n",
    "    h = model.fit(train_ds, validation_data=val_ds, epochs=200, callbacks=[rp, es])\n",
    "    # Do 5 epochs with a lower learning rate\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-5), metrics=[\"accuracy\"])\n",
    "    h = model.fit(val_ds, epochs=5)\n",
    "else:\n",
    "    h = model.fit(train_ds, epochs=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"images2/test\",\n",
    "    validation_split=None,\n",
    "    seed=42,\n",
    "    image_size=input_shape,\n",
    "    batch_size=2000,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    color_mode='rgb',\n",
    ")\n",
    "for image_batch, labels_batch in test_ds:\n",
    "  y_test_true = np.array(labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ds) # Predict class probabilities as 2 => [0.1, 0, 0.9, 0, 0, 0, 0, 0, 0, 0]\n",
    "Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels\n",
    "Y_test_treu = np.argmax(y_test_true, 1) # Decode Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10)) # Set Figure\n",
    "\n",
    "mat = confusion_matrix(Y_test_treu, Y_pred) # Confusion matrix\n",
    "\n",
    "# Plot Confusion matrix\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False, cmap=plt.cm.Blues, fmt='.0f')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(Y_test_treu, Y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/le_name_mapping.json', 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "    le = LabelEncoder()\n",
    "mapping['classes'] = [mapping[str(int(i))] for i in range(9)]\n",
    "le.classes_ = np.array(mapping['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "\n",
    "importlib.reload(utils)\n",
    "from utils import plot_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.resources import path\n",
    "\n",
    "\n",
    "plot_cm(Y_test_treu, Y_pred, le, save=1, title='Confusion Matrix: CNN Model', figname='cnn_cm', save_path='figures/CNN/')\n",
    "\n",
    "proportion_correct = f1_score(Y_test_treu, Y_pred, average='macro')\n",
    "print('Test Accuracy: {}'.format(proportion_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db3441f3efc18b286252faba8848b9af7d49db2dc5505bf705b457c48ff7d418"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
